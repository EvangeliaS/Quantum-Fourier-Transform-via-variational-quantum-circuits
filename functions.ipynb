{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a71ea739",
   "metadata": {},
   "source": [
    "# Quantum Fourier Transform via variational quantum circuits\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cf40054",
   "metadata": {},
   "source": [
    "Steiropoulou Evangelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c3be74b",
   "metadata": {},
   "source": [
    "## Pauli Matrices:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35bce6ea",
   "metadata": {},
   "source": [
    "### Pauli-X matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d78161",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = [[0,1],[1,0]]\n",
    "ss1 = torch.tensor(ss1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4dc6c11",
   "metadata": {},
   "source": [
    "### Pauli-Y matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss2 = [[0,-1j],[1j,0]]\n",
    "ss2 = torch.tensor(ss2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c89ed458",
   "metadata": {},
   "source": [
    "### Pauli-Z matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss3 = [[1,0],[0,-1]]\n",
    "ss3 = torch.tensor(ss3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89928b8a",
   "metadata": {},
   "source": [
    "### Identity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss4 = torch.eye(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77da5e0e",
   "metadata": {},
   "source": [
    "## QFT matrix, row by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8 with 1/(2*sqrt(2)\n",
    "QF3 = torch.full((1,8),1/(2*torch.sqrt(torch.tensor(2.0))))\n",
    "QF3 = torch.tensor(QF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8 with 1/(2*sqrt(2), exponential(1j*pi/4)/2*sqrt(2), (1j)/2*sqrt(2), exponential(3j*pi/4)/2*sqrt(2), - 1/(2*sqrt(2), exponential(-3j*pi/4)/2*sqrt(2), -(1j)/2*sqrt(2), exponential(-1j*pi/4)/2*sqrt(2)\n",
    "QF4 = [[1/(2*torch.sqrt(torch.tensor(2.0))), (torch.exp(1j*torch.tensor(np.pi/4)))/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0))) , torch.exp(3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))),-1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))) , -1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF4 = torch.tensor(QF4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8, with 1/(2*sqrt(2), (1j)/2*sqrt(2), - 1/(2*sqrt(2),  -(1j)/2*sqrt(2), 1/(2*sqrt(2), (1j)/2*sqrt(2), - 1/(2*sqrt(2),  -(1j)/2*sqrt(2)\n",
    "QF5 = [[1/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0))), 1/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF5 = torch.tensor(QF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33cec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8, with 1/(2*sqrt(2), exponential(3j*pi/4)/2*sqrt(2), -(1j)/2*sqrt(2), exponential(1j*pi/4)/2*sqrt(2), - 1/(2*sqrt(2),  exponential(-1j*pi/4)/2*sqrt(2), (1j)/2*sqrt(2), exponential(-3j*pi/4)/2*sqrt(2)\n",
    "QF6 = [[1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))),-1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))) , 1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF6 = torch.tensor(QF6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8 with 1/(2*sqr(2) and -1/(2*sqr(2)\n",
    "QF7 = [[1/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), 1/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), 1/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), 1/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF7 = torch.tensor(QF7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f303fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "QF8 = [[1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))) , -1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF8 = torch.tensor(QF8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e31ed7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#fill a tensor 1*8, with 1/(2*sqrt(2), (-1j)/2*sqrt(2), - 1/(2*sqrt(2),  (1j)/2*sqrt(2), 1/(2*sqrt(2), (-1j)/2*sqrt(2), - 1/(2*sqrt(2),  (1j)/2*sqrt(2)\n",
    "QF9 = [[1/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0))), 1/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0))), -1/(2*torch.sqrt(torch.tensor(2.0))), 1j/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF9 = torch.tensor(QF9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66ed9440",
   "metadata": {},
   "source": [
    "### QFT matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill a tensor 1*8 with 1/(2*sqrt(2), exponential(-1j*pi/4)/2*sqrt(2), (-1j)/2*sqrt(2), exponential(-3j*pi/4)/2*sqrt(2), - 1/(2*sqrt(2), exponential(3j*pi/4)/2*sqrt(2), (1j)/2*sqrt(2), exponential(1j*pi/4)/2*sqrt(2)\n",
    "QF10 = [[1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))), -1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(-3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))),-1/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(3j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0))) , 1j/(2*torch.sqrt(torch.tensor(2.0))), torch.exp(1j*torch.tensor(np.pi/4))/(2*torch.sqrt(torch.tensor(2.0)))]]\n",
    "QF10 = torch.tensor(QF10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5fbabe9",
   "metadata": {},
   "source": [
    "$\\large \n",
    "\\frac{1}{\\sqrt{8}} \\begin{bmatrix}\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\\n",
    "1 & e^{i\\frac{\\pi}{4}} & e^{i\\frac{\\pi}{2}} & e^{i\\frac{3\\pi}{4}} & e^{i\\pi} & e^{i\\frac{5\\pi}{4}} & e^{i\\frac{3\\pi}{2}} & e^{i\\frac{7\\pi}{4}} \\\\\n",
    "1 & e^{i\\frac{\\pi}{2}} & e^{i\\pi} & e^{i\\frac{3\\pi}{2}} & 1 & e^{i\\frac{\\pi}{2}} & e^{i\\pi} & e^{i\\frac{3\\pi}{2}} \\\\\n",
    "1 & e^{i\\frac{3\\pi}{4}} & e^{i\\frac{3\\pi}{2}} & e^{i\\frac{9\\pi}{4}} & e^{i\\pi} & e^{i\\frac{5\\pi}{4}} & e^{i\\frac{7\\pi}{2}} & e^{i\\frac{15\\pi}{4}} \\\\\n",
    "1 & e^{i\\pi} & 1 & e^{i\\pi} & 1 & e^{i\\pi} & 1 & e^{i\\pi} \\\\\n",
    "1 & e^{i\\frac{5\\pi}{4}} & e^{i\\frac{\\pi}{2}} & e^{i\\frac{7\\pi}{4}} & e^{i\\pi} & e^{i\\frac{\\pi}{4}} & e^{i\\frac{\\pi}{2}} & e^{i\\frac{3\\pi}{4}} \\\\\n",
    "1 & e^{i\\frac{3\\pi}{2}} & e^{i\\pi} & e^{i\\frac{7\\pi}{2}} & 1 & e^{i\\frac{\\pi}{2}} & e^{i\\pi} & e^{i\\frac{3\\pi}{2}} \\\\\n",
    "1 & e^{i\\frac{7\\pi}{4}} & e^{i\\frac{3\\pi}{2}} & e^{i\\frac{15\\pi}{4}} & e^{i\\pi} & e^{i\\frac{3\\pi}{4}} & e^{i\\frac{7\\pi}{2}} & e^{i\\frac{15\\pi}{4}}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce7875",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#make tensor with all the above tensors in it\n",
    "QF = torch.cat((QF3, QF4, QF5, QF6, QF7, QF8, QF9, QF10), 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9fa7360",
   "metadata": {},
   "source": [
    "## Generators:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0bea9b9",
   "metadata": {},
   "source": [
    "Here we create the generators, the quantum gates that are goint to be used in the circuit. The generators, are combinations of Kronecker products of the gates we mentioned above."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89dd14a0",
   "metadata": {},
   "source": [
    "### Single qubit gates:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c423ab2c",
   "metadata": {},
   "source": [
    "##### (1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549dd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = torch.kron(ss1, ss4)\n",
    "c1 = torch.kron(c1, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebe63c94",
   "metadata": {},
   "source": [
    "#### (4,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = torch.kron(ss4, ss2)\n",
    "c2 = torch.kron(c2, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77c9c693",
   "metadata": {},
   "source": [
    "#### (4,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd26d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c3 = torch.kron(ss4, ss3)\n",
    "c3 = torch.kron(c3, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c842d3c4",
   "metadata": {},
   "source": [
    "#### (4,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886907ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = torch.kron(ss4, ss1)\n",
    "c4 = torch.kron(c4, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7b99c3",
   "metadata": {},
   "source": [
    "#### (4,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6206f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c5 = torch.kron(ss4, ss4)\n",
    "c5 = torch.kron(c5, ss3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5fd5018",
   "metadata": {},
   "source": [
    "### Two - qubit gates:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a8d8e3a",
   "metadata": {},
   "source": [
    "#### (4,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c6 = torch.kron(ss4, ss3)\n",
    "c6 = torch.kron(c6, ss3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54850764",
   "metadata": {},
   "source": [
    "#### (4,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c7 = torch.kron(ss4, ss1)\n",
    "c7 = torch.kron(c7, ss3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9d2ff7f",
   "metadata": {},
   "source": [
    "#### (1,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c8 = torch.kron(ss1, ss1)\n",
    "c8 = torch.kron(c8, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a58ce48a",
   "metadata": {},
   "source": [
    "#### (1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "c9 = torch.kron(ss1, ss2)\n",
    "c9 = torch.kron(c9, ss4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c879e39",
   "metadata": {},
   "source": [
    "#### (3,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a277ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "c10 = torch.kron(ss3, ss4)\n",
    "c10 = torch.kron(c10, ss2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f8f2c37",
   "metadata": {},
   "source": [
    "#### (1,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "c11 = torch.kron(ss1, ss4)\n",
    "c11 = torch.kron(c11, ss3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e1d300b",
   "metadata": {},
   "source": [
    "In vv3 we will add all the generators, for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c1 - c5 are single qubit gates, c6 - c11 are two qubit gates\n",
    "vv3 = torch.stack((c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "079fd6b6",
   "metadata": {},
   "source": [
    "## Variational Gates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gi_, j_, k_, x_ := MatrixExp[I x KroneckerProduct[Assi, ssj, ssk]]\n",
    "G = torch.zeros(11, 8, 8, dtype=torch.complex64)\n",
    "for i in range(G.size(dim = 0)):\n",
    "    G[i]= torch.linalg.matrix_exp(1j*vv3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ceec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gx(x):\n",
    "    Gx = torch.zeros(11, 8, 8, dtype=torch.complex64)\n",
    "    for i in range(Gx.size(dim = 0)):\n",
    "        Gx[i] = torch.tensor(scipy.linalg.fractional_matrix_power(G[i], x)) #G to the power of x\n",
    "    return Gx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc71e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find conjugate transpose of QF\n",
    "B = torch.conj(torch.transpose(QF, 0,1))\n",
    "B.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e269ae51",
   "metadata": {},
   "source": [
    "## Circuit generator: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7019804a",
   "metadata": {},
   "source": [
    "The circuit created below, was firstly designed by hand, in order to combine both single and 2-qubit variational gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa9e6a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_circuit(x_var, parameters_num):\n",
    "    Gm = []\n",
    "    # loop over the x values to generate the corresponding G matrices\n",
    "    for i in range(x_var.size(dim=0)):\n",
    "        Gx_i = torch.zeros(11, 8, 8, dtype=torch.complex64)\n",
    "        Gx_i = Gx(x_var[i].item())\n",
    "        Gm.append(Gx_i)\n",
    "\n",
    "    # multiply the 18 G matrices to get the final G matrix/circuit\n",
    "    i = 0\n",
    "\n",
    "    G1 = Gm[i][5]   #get the first 2-qubit gate(of the first x-modified Gx_i(i==0)), 4-3-3\n",
    "    G2 = Gm[i+1][1] #get the second single qubit gate, 4-2-4\n",
    "    G3 = Gm[i+2][4] #get the last single qubit gate 4-4-3\n",
    "    G4 = Gm[i+3][7] #1-1-4\n",
    "    G5 = Gm[i+4][0] #1-4-4\n",
    "    G6 = Gm[i+5][2] #4-3-4\n",
    "    G7 = Gm[i+6][9] #3-4-2\n",
    "    G8 = Gm[i+7][4] #4-4-3\n",
    "    G9 = Gm[i+8][0] #1-4-4\n",
    "    G10 = Gm[i+9][6] #4-1-3\n",
    "    G11 = Gm[i+10][2] #4-3-4\n",
    "    G12 = Gm[i+11][4] #4-4-3\n",
    "    G13 = Gm[i+12][8] #1-2-4\n",
    "    G14 = Gm[i+13][0] #1-4-4\n",
    "    G15 = Gm[i+14][3] #4-1-4\n",
    "    G16 = Gm[i+15][10]#1-4-3\n",
    "    G17 = Gm[i+16][0] #1-4-4\n",
    "    G18 = Gm[i+17][4] #4-4-3\n",
    "\n",
    "    G_final = G1@G2@G3@G4@G5@G6@G7@G8@G9@G10@G11@G12@G13@G14@G15@G16@G17@G18\n",
    "\n",
    "    #In order to expand the initial 18-parameter circuit to a n-parameter circuit, we need to add more gates at the end of the circuit.\n",
    "    #As additional gates we will use those in the initial 18-parameter circuit. For example if the desired circuit has 20 parameters, \n",
    "    #we need to add 2 additional gates to the initial 18-parameter circuit. In order to do that, we will add the first 2 gates of the initial circuit \n",
    "    #at the end of the circuit. If we want a 28-parameter circuit, we will add the first 10 gates of the initial circuit, at the end etc.\n",
    "\n",
    "    #Initial gate indices\n",
    "    gate_indices = [5, 1, 4, 7, 0, 2, 9, 4, 0, 6, 2, 4, 8, 0, 3, 10, 0, 4]  # Example gate indices\n",
    "    # Additional gates\n",
    "    G_additional = torch.eye(8, dtype=torch.complex64)  # identity matrix\n",
    "\n",
    "    # Multiply additional gates based on the number of parameters\n",
    "    for i in range(parameters_num - 18):\n",
    "        gate_idx = gate_indices[i % 18]  # Cycle through the gate_indices list\n",
    "        G_additional = G_additional @ Gm[i+18][gate_idx]\n",
    "        G_final = G_final @ G_additional # Multiply G_final with G_additional\n",
    "\n",
    "    return G_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d10cd34",
   "metadata": {},
   "source": [
    "## Cost function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d7a0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cost_function(x_var):\n",
    "    G_final = create_circuit(x_var, len(x_var))\n",
    "    cost = 1 - 1/64 * ((torch.abs(torch.trace(G_final @ B)))**2)\n",
    "    return cost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b36cfe1",
   "metadata": {},
   "source": [
    "## Optimization methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fb606",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def learning_rate_step_scheduler(learning_rate, step_size):\n",
    "    return learning_rate * step_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8562db15",
   "metadata": {},
   "source": [
    "### Gradient Descent optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function performs gradient descent of cost to find the optimal x values\n",
    "#x_var is the initial x values, gamma is the learning rate, delta is the perturbation value\n",
    "def optimize_parameters(x_var, gamma, delta):   \n",
    "    print(\"x initial is: \\n\\n\", x_var)         \n",
    "    print(\"cost initial = \", cost_function(x_var))\n",
    "    x_new = x_var.clone()\n",
    "\n",
    "    for i in range(len(x_var)):\n",
    "        x_var_sum = x_var.clone() #create a copy of the x_var tensor\n",
    "        x_var_sum[i] = x_var[i] + delta\n",
    "        cost_sum = cost_function(x_var_sum)\n",
    "\n",
    "        x_var_diff = x_var.clone()\n",
    "        x_var_diff[i] = x_var[i] - delta\n",
    "        cost_diff = cost_function(x_var_diff)\n",
    "        x_new[i] = x_var[i] - gamma * ((cost_sum - cost_diff) / (2* delta))\n",
    "\n",
    "    return x_new, cost_function(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ffdc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#function that calls the optimize_parameters function until the cost stops changing more than a certain value(epsilon)\n",
    "def gradient_descent_cost_optimizer(x_var, learning_rate, delta, epsilon, threshold, step_size):\n",
    "    iterations = 0\n",
    "    x_init, cost_init = optimize_parameters(x_var, learning_rate, delta) #get the initial cost after the first optimization\n",
    "    x_old = x_init.clone()\n",
    "    cost_old = cost_init.clone()\n",
    "    cost_history = [cost_init]  # List to store the cost at each iteration\n",
    "\n",
    "    while True:\n",
    "        print(\"ITERATION = \\n\", iterations)\n",
    "        x_new, cost_new = optimize_parameters(x_old, learning_rate, delta)\n",
    "        print(\"new cost = \", cost_new)\n",
    "        if torch.abs(cost_new - cost_old) < epsilon:\n",
    "            break\n",
    "        else:\n",
    "            if(torch.abs(cost_new - cost_old) < threshold and iterations != 0):\n",
    "                learning_rate = learning_rate_step_scheduler(learning_rate, step_size)\n",
    "                print(\"ITERATION = \", iterations, \"    LEARNING RATE = \", learning_rate, \"\\n\")\n",
    "            x_old = x_new.clone()\n",
    "            cost_old = cost_new.clone()\n",
    "            iterations += 1\n",
    "            cost_history.append(cost_new)  # Add the current cost to the history\n",
    "\n",
    "    return x_new, cost_new, iterations, cost_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bbc5dda",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f42abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform optimization on a single data point -> this will be used in the stochastic gradient descent\n",
    "def optimize_stochastic_parameters(x_var, learning_rate, delta, data_point):  # Perform optimization on a single data point\n",
    "    x_var_sum = x_var.clone()\n",
    "    x_var_sum[data_point] = x_var[data_point] + delta\n",
    "    cost_sum = cost_function(x_var_sum)\n",
    "\n",
    "    x_var_diff = x_var.clone()\n",
    "    x_var_diff[data_point] = x_var[data_point] - delta\n",
    "    cost_diff = cost_function(x_var_diff)\n",
    "\n",
    "    x_new = x_var.clone()\n",
    "    x_new[data_point] = x_var[data_point] - learning_rate* ((cost_sum - cost_diff) / (2 * delta))\n",
    "\n",
    "    return x_new, cost_function(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc1588",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(x_var, learning_rate, delta, epsilon, threshold, step_size, scheduler, num_epochs):\n",
    "    iterations = 0\n",
    "    num_data_points = len(x_var)\n",
    "    x_init, cost_init = optimize_stochastic_parameters(x_var, learning_rate, delta, np.random.randint(num_data_points))\n",
    "    x_old = x_init.clone()\n",
    "    cost_old = cost_init.clone()\n",
    "    cost_difference = torch.abs(cost_old - cost_init)\n",
    "    cost_history = [cost_init]  # List to store the cost at each iteration\n",
    "\n",
    "    while True:\n",
    "        print(\"ITERATION =\", iterations)\n",
    "        data_point = np.random.randint(num_data_points)\n",
    "        x_new, cost_new = optimize_stochastic_parameters(x_old, learning_rate, delta, data_point)\n",
    "        print(\"x new =\", x_new)\n",
    "        print(\"new cost =\", cost_new)\n",
    "\n",
    "        if torch.abs(cost_new - cost_old) != cost_difference:\n",
    "            cost_difference = torch.abs(cost_new - cost_old)\n",
    "            print(\"cost difference =\", cost_difference)\n",
    "        if iterations > num_epochs and cost_difference < epsilon:\n",
    "            break\n",
    "        else:\n",
    "            if cost_difference < threshold and iterations != 0:\n",
    "                print(\"Scheduler called\", scheduler)\n",
    "                learning_rate = scheduler(learning_rate, step_size)\n",
    "                print(\"ITERATION =\", iterations, \" LEARNING RATE =\", learning_rate, \"\\n\")\n",
    "\n",
    "            x_old = x_new.clone()\n",
    "            cost_old = cost_new.clone()\n",
    "            iterations += 1\n",
    "            cost_history.append(cost_new)  # Add the current cost to the history\n",
    "\n",
    "    return x_new, cost_new, iterations, cost_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a118d92a",
   "metadata": {},
   "source": [
    "## Execution of the program, and cost optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = [18, 22, 26, 28]\n",
    "iterations = [700, 800, 850, 900, 950] # Number of iterations for each num of parameters. Used only in stochastic gradient descent. \n",
    "#In this implementation, we perform only the gradient descent algorithm\n",
    "\n",
    "counter = 1  # Initialize the counter\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "for algorithm in [gradient_descent_cost_optimizer]:\n",
    "    for i, j in zip(num_parameters, iterations):\n",
    "\n",
    "        # Create an empty list to store the results\n",
    "        results_algorithm = []\n",
    "\n",
    "        # Count time for each iteration\n",
    "        start = time.time()\n",
    "        x_var = torch.rand(i, dtype=torch.float32) * 2 * np.pi\n",
    "        print(\"Algorithm is: \", algorithm.__name__, \"\\n\")\n",
    "        print(\"Number of parameters is: \", i, \"\\n\")\n",
    "        print(\"x initial is: \\n\", x_var, \"\\n\")\n",
    "\n",
    "        if algorithm == stochastic_gradient_descent:\n",
    "            learning_rate = 0.05\n",
    "            delta = 0.0005\n",
    "            epsilon = 0.1\n",
    "            threshold = 0.00001\n",
    "            step_size = 0.1\n",
    "            x, cost, iters, cost_history = stochastic_gradient_descent(x_var, learning_rate, delta, epsilon, threshold, step_size, learning_rate_step_scheduler,j)\n",
    "        else:\n",
    "            learning_rate =  0.05 \n",
    "            delta = 0.005 \n",
    "            epsilon =  1e-08 \n",
    "            threshold =  0.0001 \n",
    "            step_size =   0.1 \n",
    "            x, cost, iters, cost_history = gradient_descent_cost_optimizer(x_var, learning_rate, delta, epsilon, threshold, step_size, j)\n",
    "\n",
    "        results_algorithm.append((x_var, cost_function(x_var), x, iters, cost))\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Parameters are: \\n\" , i, \" X INITIAL is:\\n\", x_var)\n",
    "        print(\"initial cost: \", cost_function(x_var))\n",
    "        print(\"    X FINAL is:\\n\\n\", x)\n",
    "        print(\"iterations =\", iters, \"final cost: \", cost)\n",
    "        print(\"time taken =\", end - start, \"\\n\\n\")\n",
    "        print(\"learning_rate = \", learning_rate, \"\\n\")\n",
    "        print(\"delta = \", delta, \"\\n\")\n",
    "        print(\"epsilon = \", epsilon, \"\\n\")\n",
    "        print(\"threshold = \", threshold, \"\\n\")\n",
    "        print(\"step_size = \", step_size, \"\\n\")\n",
    "        \n",
    "        cost_history_np = np.array([cost.detach().numpy() for cost in cost_history])\n",
    "\n",
    "        # Plot the cost progression\n",
    "        plt.figure()\n",
    "        plt.plot(cost_history_np)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.title(f'Cost Progression for: {i} Parameters, {algorithm.__name__}')\n",
    "\n",
    "        plt.ylim(bottom=0.0, top=1)\n",
    "\n",
    "        # Show the plot without blocking program execution\n",
    "        plt.show(block=False)\n",
    "\n",
    "        # Save the figure as a PNG file\n",
    "        filename = f'cost_progression_{i}_{algorithm.__name__}_{counter}.png'\n",
    "        plt.savefig(filename)\n",
    "\n",
    "        # Increment the counter\n",
    "        counter += 1\n",
    "\n",
    "        # Append the results to the list\n",
    "        for result in results_algorithm:\n",
    "            results.append({\n",
    "                'Algorithm': algorithm.__name__,\n",
    "                'Number of Parameters': i,\n",
    "                'Initial Values': result[0].detach().numpy(),\n",
    "                'Final Values': result[2].detach().numpy(),\n",
    "                'Iterations': result[3],\n",
    "                'Initial Cost': result[1].item(),\n",
    "                'Final Cost': result[4].item()\n",
    "            })\n",
    "\n",
    "    # Open the file in write mode\n",
    "    output = f'{i}_{algorithm.__name__}_{counter}.txt'\n",
    "    with open(output, 'a') as file:\n",
    "        # Iterate over the list and write each element to the file\n",
    "        for item in results_algorithm:\n",
    "            file.write(str(item) + '\\n')  # Add a newline character after each item"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
